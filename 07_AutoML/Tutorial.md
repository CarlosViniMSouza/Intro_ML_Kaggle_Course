## Introduction
When applying machine learning to real-world data, there are a lot of steps involved in the process -- starting 
with collecting the data and ending with generating predictions. (We work with the seven steps of machine learning, 
as defined by [Yufeng Guo](https://towardsdatascience.com/the-7-steps-of-machine-learning-2877d7e5548e) here.)

![img1](https://i.imgur.com/mqTCqBR.png)

It all begins with Step 1: Gather the data. In industry, there are important considerations you need to take into 
account when building a dataset, such as [target leakage](https://www.kaggle.com/alexisbcook/data-leakage). When 
participating in a Kaggle competition, this step is already completed for you.

In the [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) and the [Intermediate 
Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) courses, you can learn how to:

**° Step 2:** Prepare the data - Deal with [missing values](https://www.kaggle.com/alexisbcook/missing-values) and 
[categorical data](https://www.kaggle.com/alexisbcook/categorical-variables).('Feature engineering' is covered in a 
separate course.)

**° Step 4:** Train the model - Fit [decision trees](https://www.kaggle.com/dansbecker/
your-first-machine-learning-model) and [random forests](https://www.kaggle.com/dansbecker/random-forests) to 
patterns in training data.

**° Step 5:** Evaluate the model - Use a [validation set](https://www.kaggle.com/dansbecker/model-validation) to 
assess how well a trained model performs on unseen data.

**° Step 6:** Tune parameters - Tune parameters to get better performance from [XGBoost models](https://www.kaggle.com/alexisbcook/xgboost).

**° Step 7:** Get predictions - Generate predictions with a trained model and [submit your results to a [Kaggle competition](https://www.kaggle.com/carlosvinimsouza/exercise-machine-learning-competitions/edit).

